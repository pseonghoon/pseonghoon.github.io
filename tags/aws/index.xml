<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on 박성훈의 블로그</title>
    <link>https://pseonghoon.github.io/tags/aws/</link>
    <description>Recent content in AWS on 박성훈의 블로그</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>2020</copyright>
    <lastBuildDate>Tue, 01 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://pseonghoon.github.io/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[kubernetes-event-exporter] 오래된 쿠버네티스 이벤트 조회</title>
      <link>https://pseonghoon.github.io/post/kubernetes-event-exporter/</link>
      <pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pseonghoon.github.io/post/kubernetes-event-exporter/</guid>
      <description>
        
          &lt;p&gt;쿠버네티스에서 &lt;a href=&#34;https://kubernetes.io/docs/tasks/debug/debug-application/&#34;&gt;애플리케이션 트러블슈팅&lt;/a&gt;을 할 때 쿠버네티스 이벤트(Kubernetes event)가 단서를 제공하는 경우가 많다.  하지만 etcd의 저장 공간 제한 때문에 길어도 며칠 정도밖에 보관되지 않아 시간이 지나면 이벤트를 확인할 수 없어서 원인 파악이 어려워지는 문제가 있다.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/opsgenie/kubernetes-event-exporter&#34;&gt;kubernetes-event-exporter&lt;/a&gt;를 활용하면 이벤트를 로그로 남겨 AWS CloudWatch Logs 나 Elasticsearch 같은 로그 처리 시스템에 저장하고 필요할 때 조회할 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; 쿠버네티스 이벤트는 &lt;code&gt;kubectl get event&lt;/code&gt;, &lt;code&gt;kubectl describe&lt;/code&gt; 명령으로 확인할 수 있다.&lt;/p&gt;
&lt;h1 id=&#34;kubernetes-event-exporter&#34;&gt;kubernetes-event-exporter&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/resmoio/kubernetes-event-exporter/blob/master/README.md&#34;&gt;https://github.com/resmoio/kubernetes-event-exporter/blob/master/README.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;위 가이드에선 이벤트를 모니터링해서 통보하는 설정을 좀 더 비중있게 다루고 있으나 이벤트는 로그로 남기는 것이 더 적합한 것 같다. 모니터링은 Prometehus metric 같은 것으로 하고 문제의 원인을 파악할 때 이벤트 로그를 꺼내보면 된다.&lt;/p&gt;
&lt;h1 id=&#34;예제-구성&#34;&gt;예제 구성&lt;/h1&gt;
&lt;p&gt;AWS의 CloudWatch Logs를 활용하는 예제이다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;kubernetes-event-exporter는 표준 출력(standard output)으로 이벤트의 로그를 남긴다. 로그는 JSON 형식이다.&lt;/li&gt;
&lt;li&gt;DaemonSet으로 실행되는 fluent-bit가 kubernetes-event-exporter 의 표준 출력을 CloudWatch Logs로 전송한다.&lt;/li&gt;
&lt;li&gt;CloudWatch Logs Insights 의 쿼리를 사용해 문제가 발생한 시점의 이벤트를 조회한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;helm-차트-설치-방법&#34;&gt;Helm 차트 설치 방법&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/main/bitnami/kubernetes-event-exporter&#34;&gt;Bitnami에서 제공하는 Helm 차트&lt;/a&gt;를 설치하는 방법이다.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; 차트 버전 1.5.2 에서 테스트했으며 이 포스트를 쓰는 시점의 최신 차트 버전인 2.0.0 까지는 같은 방식으로 해야 하는 것을 확인했다.&lt;/p&gt;
&lt;p&gt;아래 명령으로 설치할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;helm upgrade event-exporter bitnami/kubernetes-event-exporter \
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;  --install \
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;  --create-namespace \
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;  --namespace event-exporter \
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;  --version 1.5.2 \     
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;  --values values.yaml
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;kubectl apply -f more-rbac.yaml
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;values.yaml&lt;/code&gt; 내용 :&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;repository&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;public.ecr.aws/bitnami/kubernetes-event-exporter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rbac&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# view ClusterRole 을 바인딩하는데 이 권한만으론 부족함. more-rbac.yaml에서  권한을 추가로 부여한다.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logLevel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;route&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;receiver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;dump&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;receivers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;dump&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stdout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;100Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;more-rbac.yaml&lt;/code&gt; 내용:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterRole&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;event-exporter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;nodes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;verbs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;watch&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterRoleBinding&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;event-exporter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;roleRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;21&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterRole&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;event-exporter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;23&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subjects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ServiceAccount&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;event-exporter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;event-exporter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;valuesyaml-설명&#34;&gt;values.yaml 설명&lt;/h2&gt;
&lt;p&gt;쿠버네티스의 표준적인 방법대로 로그를 표준 출력으로 내보내게 설정한다. 아래 문서의 가이드대로 config 차트 파라미터를 설정하고 있다.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/resmoio/kubernetes-event-exporter/blob/master/README.md#stdout&#34;&gt;https://github.com/resmoio/kubernetes-event-exporter/blob/master/README.md#stdout&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;이렇게 설정하면 로그가 아래처럼 JSON형식으로 출력된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;{&amp;#34;metadata&amp;#34;:{&amp;#34;name&amp;#34;:&amp;#34;kube-proxy-hcctq.171fa332d0d2fca1&amp;#34;,&amp;#34;namespace&amp;#34;:&amp;#34;kube-system&amp;#34;,&amp;#34;uid&amp;#34;:&amp;#34;813df6a8-d912-49a1-9fa6-2d74b061a66f&amp;#34;,&amp;#34;resourceVersion&amp;#34;:&amp;#34;311176937&amp;#34;,&amp;#34;creationTimestamp&amp;#34;:&amp;#34;2022-10-20T01:37:05Z&amp;#34;},&amp;#34;reason&amp;#34;:&amp;#34;NodeNotReady&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;Node is not ready&amp;#34;,&amp;#34;source&amp;#34;:{&amp;#34;component&amp;#34;:&amp;#34;node-controller&amp;#34;},&amp;#34;firstTimestamp&amp;#34;:&amp;#34;2022-10-20T01:37:05Z&amp;#34;,&amp;#34;lastTimestamp&amp;#34;:&amp;#34;2022-10-20T01:37:05Z&amp;#34;,&amp;#34;count&amp;#34;:1,&amp;#34;type&amp;#34;:&amp;#34;Warning&amp;#34;,&amp;#34;eventTime&amp;#34;:null,&amp;#34;reportingComponent&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;reportingInstance&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;involvedObject&amp;#34;:{&amp;#34;kind&amp;#34;:&amp;#34;Pod&amp;#34;,&amp;#34;namespace&amp;#34;:&amp;#34;kube-system&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;kube-proxy-hcctq&amp;#34;,&amp;#34;uid&amp;#34;:&amp;#34;19adea83-7bec-4bd4-918d-ddc39e6c4c45&amp;#34;,&amp;#34;apiVersion&amp;#34;:&amp;#34;v1&amp;#34;,&amp;#34;resourceVersion&amp;#34;:&amp;#34;311176399&amp;#34;,&amp;#34;labels&amp;#34;:{&amp;#34;controller-revision-hash&amp;#34;:&amp;#34;f6b68b794&amp;#34;,&amp;#34;k8s-app&amp;#34;:&amp;#34;kube-proxy&amp;#34;,&amp;#34;pod-template-generation&amp;#34;:&amp;#34;4&amp;#34;}}} 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; 만약 &lt;code&gt;config&lt;/code&gt; 파라미터를 설정하지 않으면 아래와 같이 로그의 내용이 빈 상태로 출력된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;{}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Helm 차트를 설치하면 아래처럼 기본 설정으로 이벤트를 표준 출력에 덤프한다는 메시지가 출력된다. 이 내용에 따르면 차트 파라미터를 따로 설정할 필요가 없는 것처럼 보이지만 실제로는 그렇지 않으니 주의해야 한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;By default, the kubernetes-event-exporter will dump events to stdout.
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;To configure additional endpoints, redeploy the chart overwritting the field &amp;#39;config&amp;#39; at your &amp;#39;values.yml&amp;#39;.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;more-rbacyaml-설명&#34;&gt;more-rbac.yaml 설명&lt;/h2&gt;
&lt;p&gt;values.yaml에서 rbac 파라미터를 true로 설정하면 view ClusterRole을 사용한다. 그런데 그것만으론 권한이 부족헤 kubernetes-event-exporter의 로그에 아래와 같은 에러가 남은다. 부족한 권한을 more-rbace.yaml 로 부여하는 것이다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;2022-10-12T23:35:24Z ERR bitnami/blacksmith-sandox/kubernetes-event-exporter-0.11.0/src/github.com/opsgenie/kubernetes-event-exporter/pkg/kube/watcher.go:75 &amp;gt; Cannot list labels of the object error=&amp;#34;nodes \&amp;#34;ip-10-255-14-142.ap-northeast-2.compute.internal\&amp;#34; is forbidden: User \&amp;#34;system:serviceaccount:event-exporter:event-exporter-kubernetes-event-exporter\&amp;#34; cannot get resource \&amp;#34;nodes\&amp;#34; in API group \&amp;#34;\&amp;#34; at the cluster scope&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;more-rbac.yaml의 예제에선 nodes에 대한 권한을 부여하고 있는데 클러스터 설정에 따라 권한을 더 부여해야 할 수도 있다.&lt;/p&gt;
&lt;h1 id=&#34;fluentbbit-로-aws-cloudwatch-logs-로-로그-전송&#34;&gt;FluentBbit 로 AWS CloudWatch Logs 로 로그 전송&lt;/h1&gt;
&lt;p&gt;AWS CloudWatch Logs 에 application 로그를 전송하려면 아래 가이드를 따르면 된다.
&lt;a href=&#34;https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-logs-FluentBit.html&#34;&gt;https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-logs-FluentBit.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;이 가이드대로 FluentBit를 설정하면 로그 내용이 JSON 형식일 때 그 내용을 &lt;code&gt;log_processed&lt;/code&gt; 필드로 쿼리할 수 있다. 다음 섹션의 쿼리 예제를 참고한다.&lt;/p&gt;
&lt;h1 id=&#34;cloudwatch-logs-에서-로그를-조회하는-예제&#34;&gt;CloudWatch Logs 에서 로그를 조회하는 예제&lt;/h1&gt;
&lt;p&gt;아래처럼 CloudWatch Logs Insights 쿼리로 검색할 수 있다.&lt;/p&gt;
&lt;p&gt;우선 조회할 로그 그룹을 /aws/containerinsights/&lt;code&gt;&amp;lt;cluster-name&amp;gt;&lt;/code&gt;/application 으로 설정한다.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://pseonghoon.github.io/post/img/log_group.png&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;아래처럼 쿼리를 실행하면 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;fields @timestamp, log_processed.involvedObject.kind as kind,
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt; log_processed.involvedObject.namespace as namespace,
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt; log_processed.involvedObject.name as object_name, log_processed.message as message 
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;| filter kubernetes.container_name = &amp;#39;event-exporter&amp;#39; and kind = &amp;#39;Pod&amp;#39;
&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;| sort @timestamp asc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;결과는 아래와 같다.
&lt;figure&gt;
    &lt;img src=&#34;https://pseonghoon.github.io/post/img/event-exporter-log-query-result.png&#34;/&gt; 
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; 실제로 이벤트가 발생한 횟수보다 kubernetes-event-exporter 에 남는 로그 수가 더 적다. 쿠버네티스는 동일한 이벤트가 근접한 시간에 여러번 발생하면 기존에 etcd에 저장된 이벤트를 업데이트하는데 아마도 kubernetes-event-exporter가 이벤트가 새로 etcd에 생성되는 경우에만 로그를 남기기 때문인 것 같다.&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>AWS CLI가 포함된 Lambda layer 만들기</title>
      <link>https://pseonghoon.github.io/post/awscli-in-labmda-layer/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://pseonghoon.github.io/post/awscli-in-labmda-layer/</guid>
      <description>
        
          &lt;p&gt;Python으로 작성된 Lambda function이 AWS CLI를 실행할 수 있도록 AWS CLI가 포함된 Lambda layer를 만드는 방법을 공유한다. AWS CLI는 다소 특이한 Python 모듈일 뿐이기 때문에 일반적인 Python 모듈의 경우에도 활용할 수 있다.&lt;/p&gt;
&lt;h1 id=&#34;lambda-layer&#34;&gt;Lambda layer&lt;/h1&gt;
&lt;p&gt;Lambda layer는 AWS Lambda 서비스에서 Lambda function이 필요로 하는 라이브러리 코드를 재활용하기 위한 도구이다. 자세한 내용은 &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html&#34;&gt;https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html&lt;/a&gt; 에서 찾을 수 있다.&lt;/p&gt;
&lt;p&gt;Python 모듈을 Lambda function의 deployment package 안에 직접 넣는 것보다 Lambda layer를 만드는 것이 편리하다. 해당 모듈을 사용하는 여러 Lambda function에서 layer를 가져다 쓰면서 재활용할 수 있기 때문이다.&lt;/p&gt;
&lt;h1 id=&#34;lambda-function에서-aws-cli를-써야-하는-경우&#34;&gt;Lambda function에서 AWS CLI를 써야 하는 경우&lt;/h1&gt;
&lt;p&gt;Python runtime을 사용하는 Lambda function에서 AWS API 호출을 하려면
AWS CLI를 실행하는 것보다 AWS의 Python SDK인 boto3 mo을 사용하는 것이 더 좋은 방법이다.
코딩하기도 편하고 boto3는 Python runtime에 포함되어 있기 때문에 바로 사용할 수 있다.&lt;/p&gt;
&lt;p&gt;AWS CLI는 아래처럼 boto3에서 해당 기능을 지원하지 않는 명령에만 사용하는 것이 좋다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;aws eks update-kubeconfig&lt;/li&gt;
&lt;li&gt;aws s3 sync&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;aws eks update-kubeconfig 명령은 Lambda function에서 EKS 클러스터에 접속할 때 kubeconfig 설정을 위해 필요하다.&lt;/p&gt;
&lt;h1 id=&#34;lambda-layer-용-zip-파일-생성-방법&#34;&gt;Lambda layer 용 zip 파일 생성 방법&lt;/h1&gt;
&lt;p&gt;우선 &lt;a href=&#34;https://github.com/pyenv/pyenv&#34;&gt;pyenv&lt;/a&gt;와 &lt;a href=&#34;https://virtualenv.pypa.io/en/latest/installation.html&#34;&gt;virutalenv&lt;/a&gt;를 설치해야 한다.&lt;/p&gt;
&lt;p&gt;pyenv로 Lambda runtime에 맞는 Python 버전을 설치한다.
예를 들어 python3.8 용 layer를 생성하기 위해 3.8.11 을 설치할 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;pyenv install 3.8.11 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://gist.github.com/pseonghoon/89a9421536016f52dff5d34a20e832dc&#34;&gt;zip-lambda-layer-awscli.sh&lt;/a&gt; 스크립트를 다운로드한 후 아래처럼 layer를 구성하는 zip 파일을 만든다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;$ sh zip-lambda-layer-awscli.sh 3.8.11 
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 생성되는 파일은 아래와 같다.&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;$ ls *.zip
&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;lambda-layer-awscli-python38.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Terraform으로 아래처럼 Lambda layer와 function을 만들 수 있다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-hcl&#34; data-lang=&#34;hcl&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 실제로는 아래처럼 aws_lambda_layer_version을 직접 만들지 말고, 이것을 생성하는 테라폼 모듈을 만들어서 재사용해야 한다.
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;resource&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;aws_lambda_layer_version&amp;#34; &amp;#34;awscli_python38&amp;#34;&lt;/span&gt; {
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;  filename&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;./lambda-layer-awscli-python38.zip&amp;#34;&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;  compatible_runtimes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;python3.8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;  }
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;resource&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;aws_lambda_function&amp;#34; &amp;#34;main&amp;#34;&lt;/span&gt; {
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;  runtime&lt;/span&gt;          &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;python3.8&amp;#34;&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;  layers&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;aws_lambda_layer_version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;awscli_python38&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;arn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Lambda function을 구성하는 Python 스크립트에서 아래처럼 사용하면 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# PATH 환경 변수에 포함된 /opt/bin/ 아래에 aws가 있어서 경로 지정을 하지 않아도 된다.&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subprocess&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;aws --version&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shell&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;check&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;zip-lambda-layer-awsclish-스크립트&#34;&gt;zip-lambda-layer-awscli.sh 스크립트&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://gist.github.com/pseonghoon/89a9421536016f52dff5d34a20e832dc&#34;&gt;zip-lambda-layer-awscli.sh&lt;/a&gt;의 내용은 아래와 같다.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/pseonghoon/89a9421536016f52dff5d34a20e832dc.js&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;참고-zip-파일-구성&#34;&gt;[참고] zip 파일 구성&lt;/h1&gt;
&lt;p&gt;bin/ 아래에 aws 명령과 그것이 의존하는 Python 모듈을 설치한다.&lt;/p&gt;
&lt;p&gt;zip 파일 내의 bin/ 디렉토리는 Lambda 실행 환경에선 /opt/bin/ 디렉토리가 된다.
/opt/bin/ 디렉토리는 Lambda function의 PATH 환경 변수에 포함되어 있기 때문에 Lambda function은 aws 명령을 경로 지정 없이 실행할 수 있다.&lt;/p&gt;
&lt;p&gt;Python은 sys.path 변수에 포함된 디렉토리에서 import하는 module들을 찾는다. Lambda function의 sys.path 변수는 /opt/ 아래 다양한 디렉토리를 포함한다.
하지만 이 layer에 포함된 모듈들은 lambda function이 아니라 /opt/bin/aws 스크립트에서 import 하기 위한 것이다. 그런데 aws 명령의 sys.path 변수에는 /opt/ 아래 디렉토리들이 포함되지 않는다. aws 명령이 awscli 모듈을 찾을 수 있게 하려면 명령과 동일한 디렉토리인 /opt/bin/ 아래에 모듈을 넣어야 한다.&lt;/p&gt;
&lt;p&gt;Lambda는 layer를 포함한 &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html&#34;&gt;deployment package의 크기를 제한&lt;/a&gt;한다. 따라서 zip 파일과 deployment package의 크기를 줄이기 위해 Python 버전별로 layer를 따로 만든다.&lt;/p&gt;
&lt;h1 id=&#34;참고한-문서&#34;&gt;참고한 문서&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/invocation-layers.html&#34;&gt;https://docs.aws.amazon.com/lambda/latest/dg/invocation-layers.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html&#34;&gt;https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/python-package.html&#34;&gt;https://docs.aws.amazon.com/lambda/latest/dg/python-package.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bezdelev.com/hacking/aws-cli-inside-lambda-layer-aws-s3-sync/&#34;&gt;https://bezdelev.com/hacking/aws-cli-inside-lambda-layer-aws-s3-sync/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
        
      </description>
    </item>
    
    <item>
      <title>오해하기 쉬운 EKS 클러스터의 subnet 설정</title>
      <link>https://pseonghoon.github.io/post/eks-subnet/</link>
      <pubDate>Sat, 17 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pseonghoon.github.io/post/eks-subnet/</guid>
      <description>
        
          &lt;p&gt;EKS 클러스터를 생성할 때 subnet 설정의 의미를 오해하기 쉽다.&lt;/p&gt;
&lt;p&gt;이 설정은 &lt;u&gt;EKS master가 worker node와 통신하기 위해 사용할 subnet&lt;/u&gt;을 지정하는 것이다. 그런데 worker node가 사용하는 모든 subnet을 지정하는 것으로 잘못 이해하면 나중에 worker node들이 사용할 subnet을 추가하기 위해 EKS 클러스터(master)를 재생성해야 하는 것으로 오해할 수 있다.&lt;/p&gt;
&lt;p&gt;특히 Terraform 등 코드로 클러스터를 만들 때 argument의 이름만 보고 오해하기 쉽다.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/reference/eks/create-cluster.html#options&#34;&gt;AWSCLI 문서&lt;/a&gt; 중 클러스터 subnetIds에 대한 설명이 아래와 같다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;subnetIds -&amp;gt; (list)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Specify subnets for your Amazon EKS worker nodes.
Amazon EKS creates cross-account elastic network interfaces in these
subnets to allow communication between your worker nodes and the Kubernetes control plane.&lt;/p&gt;
&lt;p&gt;(string)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;첫 문장을 보고 worker node들이 사용하는 모든 subnet으로 설정해야 한다고 생각할 수 있는데 그렇지 않다. 첫 문장에 오해의 소지가 있다.&lt;/p&gt;
&lt;p&gt;이어지는 내용을 차분히 읽으면 알 수 있듯이, control plane (master)이 해당 subnet에 network interface를 생성해서 worker node들과 통신할 수 있으면 된다.
VPC 내의 subnet들은 서로 라우팅이 되니 &lt;mark&gt; VPC 내의 private subnet 중 아무 것이나 사용해도 된다&lt;/mark&gt;. 단, 서로 다른 AZ에 있는 2개 이상의 subnet으로 설정해야 한다.&lt;/p&gt;
&lt;h2 id=&#34;잘못-이해했을-때의-문제&#34;&gt;잘못 이해했을 때의 문제&lt;/h2&gt;
&lt;p&gt;이것을 잘못 이해하면 곤란한 상황에 처할 수 있다.
EKS에선 Pod들도 실제 VPC의 IP를 사용하니 많은 IP가 필요하다.&lt;/p&gt;
&lt;p&gt;처음에 클러스터의 규모를 작게 예상해서 worker node가 사용하는 subnet에 작은 크기의 IP 대역을 할당할 수 있다.
이후에 IP가 부족하면 subnet을 늘려야 하는데, 설정의 의미를 오해하면 EKS cluster(master)의 subnet도 그에 맞게 변경해야 한다고 생각하게 된다.&lt;/p&gt;
&lt;p&gt;문제는 &lt;a href=&#34;(https://docs.aws.amazon.com/eks/latest/APIReference/API_UpdateClusterConfig.html)&#34;&gt;AWS EKS API&lt;/a&gt;가 subnetIds 속성의 변경을 허용하지 않는다는 것이다.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/APIReference/API_UpdateClusterConfig.html&#34;&gt;API 문서&lt;/a&gt;에서도 아래처럼 알려주고 있다. (2020년 10월 16일 기준)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;
At this time, you can not update the subnets or security group IDs for an existing cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Terraform에서 &lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_cluster#subnet_ids&#34;&gt;subnet_ids&lt;/a&gt; 값을 변경하고 terraform apply를 실행하면 클러스터를 삭제하고 새로 생성한다.&lt;/p&gt;
&lt;p&gt;결국 IP 대역을 늘리기 위해 불필요하게 cluster를 삭제하고 새로 만드는 수고를 하게 될 수 있다.
아니면 IP 대역을 늘리는 것이 쉬운 일이 아니라고 생각해서 처음부터 지나치게 큰 IP 대역을 할당할 수도 있다.&lt;/p&gt;
&lt;h2 id=&#34;올바른-설정의-예&#34;&gt;올바른 설정의 예&lt;/h2&gt;
&lt;p&gt;범용으로 사용하는 private subnet (private_subnet이라 하자)과 eks worker 전용 subnet (eks_worker_subnet)을 따로 만들었다고 가정하자.&lt;/p&gt;
&lt;p&gt;EKS 클러스터에는 private_subnet을 설정하면 된다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Terraform 코드 예제&lt;/strong&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-hcl&#34; data-lang=&#34;hcl&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;resource&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;aws_eks_cluster&amp;#34; &amp;#34;main&amp;#34;&lt;/span&gt; {
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;  name&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;main&amp;#34;&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;  role_arn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;terraform_remote_state&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;tf_iam&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;common_role_arn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;eks_master&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;vpc_config&lt;/span&gt; {
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;    security_group_ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;terraform_remote_state&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;tf_sg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;eks_sg_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;eks_master&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;    # 2개 이상의 AZ를 포함하기만 하면 되므로 2개만 잘라서 쓴다. 
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;    # 2개로 고정했기 때문에 나중에 만약 private_subnet_ids에 새로운 subnet이 추가되어도 여기를 수정하지 않아도 된다.
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;    subnet_ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;slice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;terraform_remote_state&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;tf_vpc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;private_subnet_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;  }
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;eks_woker_subnet은 worker node를 생성하는 Auto Scaling Group에 설정하면 된다.
Terraform 이라면 aws_autoscaling_group의 &lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#vpc_zone_identifier&#34;&gt;vpc_zone_identifier&lt;/a&gt;에 설정하면 된다.&lt;/p&gt;
&lt;p&gt;이 argument는 Auto Scaling Group 재생성 없이 업데이트가 가능하기 때문에 Pod이 사용할 IP가 모자라면 쉽게 subnet을 추가해서 해결할 수 있다.&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes에서 NFS 사용하기</title>
      <link>https://pseonghoon.github.io/post/k8s-and-nfs/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pseonghoon.github.io/post/k8s-and-nfs/</guid>
      <description>
        
          &lt;p&gt;Pod에서 NFS를 volume으로 사용하기 위해 &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/#nfs&#34;&gt;공식 문서&lt;/a&gt;의 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/&#34;&gt;예제&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;를 참고하는 경우가 많을 것인데, 보완 설명을 하려고 한다. AWS EFS를 NFS 서버로 사용할 때 편리하게 쓸 수 있는 efs-provisioner 도 간략하게 소개한다.&lt;/p&gt;
&lt;p&gt;공식 문서에서 소개하는 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/&#34;&gt;예제&lt;/a&gt;는 클러스터 내부에서 NFS 서버를 운영한다. 그리고 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-pv.yaml&#34;&gt;PV&lt;/a&gt;(PersistentVolume)와 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-pvc.yaml&#34;&gt;PVC&lt;/a&gt;(PersistentVolumeClaim)를 정의해서 Pod이 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-web-rc.yaml#L29-L30&#34;&gt;PVC를 volume으로 지정&lt;/a&gt;하는 방식을 쓰고 있다.&lt;/p&gt;
&lt;p&gt;더 실용적이고 간단한 방법은 PV와 PVC를 만들지 않고 아래처럼 Pod의 volume으로 NFS를 직접 지정하는 것이다. NFS 서버도 클러스터 밖에서 운영하는 것이 좋다. AWS라면 &lt;a href=&#34;https://aws.amazon.com/efs/&#34;&gt;EFS 서비스&lt;/a&gt;를 사용하면 된다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nfs-example&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nfs-example&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nfs-example&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;           &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/nfs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;             &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;efs-vol&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt;21&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;efs-vol&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt;23&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nfs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 예제로 EFS를 사용했지만 일반적인 NFS 서버면 된다.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;fs-f9352198.efs.ap-northeast-2.amazonaws.com &lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;ln&#34;&gt;27&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;nfs 타입의 volume에서 설정할 수 있는 field는 &lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#nfsvolumesource-v1-core&#34;&gt;API reference&lt;/a&gt;를 참고했다.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;official-nfs-example&#34;&gt;공식 문서 예제 보완 설명&lt;/h1&gt;
&lt;p&gt;먼저 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/&#34;&gt;예제&lt;/a&gt;의 내용을 따라하면서 충분히 이해한 후 이 포스트를 읽으면 더 도움이 될 것이다.
예제는 관련 개념을 파악하는데 도움이 되지만 실무에서 활용하려면 유의할 점이 있다.&lt;/p&gt;
&lt;p&gt;우선 NFS 서버를 클러스터 내부에서 운영하고 있다. 예제로는 좋은 접근이지만 그대로 활용하기에는 아래와 같은 한계가 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NFS 서버의 위치를 DNS name 대신 IP로 하드코딩한다.&lt;/li&gt;
&lt;li&gt;Google Cloud의 Persistent Disk를 사용했다. Persistent Disk는 zone에 종속된다. (AWS라면 EBS와 AZ에 해당)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;그리고 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-pv.yaml&#34;&gt;PV&lt;/a&gt;와 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-pvc.yaml&#34;&gt;PVC&lt;/a&gt;를 정의한 후 Pod이 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-web-rc.yaml#L29-L30&#34;&gt;PVC를 volume으로 지정&lt;/a&gt;하는데, 맥락 상 어색한 방법이다.&lt;/p&gt;
&lt;h4 id=&#34;hardcodedip&#34;&gt;IP 하드코딩&lt;/h4&gt;
&lt;p&gt;예제에선 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-server-service.yaml&#34;&gt;nfs-server&lt;/a&gt; 라는 Service를 정의한다. 그래서 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-pv.yaml&#34;&gt;PV 정의&lt;/a&gt;에서 DNS name인 &lt;strong&gt;nfs-server.default.svc.cluster.local&lt;/strong&gt; 로 NFS 서버의 위치를 지정하고 있지만 이렇게는 접속이 안된다. 해결하기 위한 임시방편으로 Service의 clusterIP를 사람이 확인해서 코드를 고치는 방식을 안내하고 있다.&lt;/p&gt;
&lt;p&gt;여기서 DNS name을 사용할 수 없는 이유가 있다. NFS mount는 Pod이 직접 하는 것이 아니라 node에서 해줘야 한다. 그런데 node는 클러스터 내의 DNS(coreDNS 등)에 쿼리를 하지 않기 때문이다. 그렇게 하도록 설정하는 것이 가능하겠지만 node의 DNS lookup이 Kubernetes 클러스터 내부 DNS를 의존하는 것은 좋은 구성이 아닐 수 있다.&lt;/p&gt;
&lt;h4 id=&#34;pvc&#34;&gt;PVC와 PV의 어색한 활용&lt;/h4&gt;
&lt;p&gt;Pod의 생애와 관계 없이 계속 유지되는 데이터가 필요하면 PV(PersistentVolume)를 반드시 써야 한다고 생각하기 쉽다. 하지만 꼭 그런 것은 아니다.&lt;/p&gt;
&lt;p&gt;PV는 PVC(PersistentVolumeClaim)없이 단독으로 volume으로 사용할 수 없다.
그럼 PVC는 왜 필요한가? PVC는 대부분의 경우 dynamic provisioning 하기 위해 사용한다. 클라우드 환경이라면 더욱 그렇다.&lt;/p&gt;
&lt;p&gt;예제에서는 이미 존재하는 NFS 서버와 path(/)를 mount한 것이기 때문에 PVC와 PV를 굳이 정의할 필요가 없다.
이 포스트에서 한 것처럼 Pod의 volume에서 바로 nfs를 사용하는 것이 더 간단하고 직관적이다.&lt;/p&gt;
&lt;p&gt;그리고, 예제에서 PVC와 PV를 binding한 방식도 적절하지 않다.
이 주제에서 별로 중요한 포인트는 아니라서 각주&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;에서 설명했으니 관심 있는 분들은 참고하셨으면 한다.&lt;/p&gt;
&lt;h1 id=&#34;efs-provisioner-소개&#34;&gt;efs-provisioner 소개&lt;/h1&gt;
&lt;p&gt;AWS에서 EFS를 사용한다면, &lt;a href=&#34;https://github.com/kubernetes-retired/external-storage/tree/master/aws/efs&#34;&gt;efs-provisioner&lt;/a&gt;를 쓰면 편리하다.&lt;/p&gt;
&lt;p&gt;오해하기 쉬운데, EFS를 Kubernets에서 사용하기 위해서 반드시 efs-provisioner를 써야하는 것은 아니다. efs-provisioner는 EFS에 기반한 volume을 dynamic provisioning할 때 사용하는 것이다. 이 포스트에서 주로 다룬 경우처럼 이미 NFS 서버와 mount할 path가 존재한다면 적합하지 않은 도구이다.&lt;/p&gt;
&lt;p&gt;이것을 사용하려면 PVC를 정의해야 하는데 PVC는 namespaced resource라서 동일한 namespace 안의 Pod만 접근할 수 있는 한계가 있다.&lt;/p&gt;
&lt;h4 id=&#34;사용-방법&#34;&gt;사용 방법&lt;/h4&gt;
&lt;p&gt;PVC를 여럿 만드는 경우에도, EFS file system을 하나만 생성하고 efs-provisioner &lt;a href=&#34;https://github.com/helm/charts/tree/master/stable/efs-provisioner&#34;&gt;Helm chart&lt;/a&gt;도 하나만 설치하면 된다.&lt;/p&gt;
&lt;p&gt;Helm chart를 설치할 때 EFS filesystem ID를 알려주면, 이것과 연계된 StorageClass를 생성한다.
여러 Pod들이 공유해야 하는 데이터가 있으면 이 StorageClass를 사용하는 PVC를 생성한 후 여러 Pod들이 동일하게 이 PVC를 volume으로 지정하면 된다.
그러면 efs-provisioner가 EFS filesystem 내에 각 PVC별로 전용 디렉토리를 만들어 제공하는 방식이다.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;참조하는 코드는 2020년 10월 10일 기준 master branch가 가리키는 commit으로 고정했다. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;공식문서의 예제에선 PVC에 이미 존재하는 PV를 binding 했다. 이것을 위해 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-pvc.yaml#L8&#34;&gt;PVC의 storageClassName 설정&lt;/a&gt;을 “”로 했는데 &lt;a href=&#34;https://github.com/kubernetes/examples/blob/bbe33f4997d781cffe9e310281e5ab4da07a07d5/staging/volumes/nfs/nfs-pv.yaml&#34;&gt;PV&lt;/a&gt;는 storageClassName을 정의하지 않았기 때문에 binding이 된 것 같다. 이런 일을 정확히 하려면 PV에 label을 달고 PVC에 &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#selector&#34;&gt;label selector&lt;/a&gt;를 설정해야 할 것이다. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
        
      </description>
    </item>
    
    <item>
      <title>코드로 인프라 관리하기 (IaC)</title>
      <link>https://pseonghoon.github.io/post/infrastructure-as-code/</link>
      <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://pseonghoon.github.io/post/infrastructure-as-code/</guid>
      <description>
        
          &lt;p&gt;&lt;code&gt;링크&lt;/code&gt;: &lt;a href=&#34;https://drive.google.com/file/d/1Bsc5hic_p8nNfGTSa8Dz4UXx49PVFOd4/view?usp=sharing&#34;&gt;코드로 인프라 관리하기 (ppt)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Games on AWS 2019에서 발표한 자료다. 당시 청중 설문에서 가장 좋은 평가를 받았다.
Infrastructure as Code, 더 나아가 자동화를 통해 무엇을 얻을 수 있는지, 잘 정착되게 하려면 어떤 것을 신경써야 하는지를 정리했다.&lt;/p&gt;
&lt;p&gt;사내에서 경영진 대상으로 발표했던 자료를 행사의 성격에 맞게 수정해서 사용했다.
2017년부터 2년 간의 구현 경험으로 쓴 것이다.&lt;/p&gt;
        
      </description>
    </item>
    
  </channel>
</rss>
